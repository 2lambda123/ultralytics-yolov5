num_classes: 9
num_classification_classes: 11
num_pose_kps: 7
image_size: [768, 544] # for cloud - d0
resize_img: [960, 544]
pose_mask_shape: [ 68, 96 ]
#heads: [ 'object_detection_image_classification_pose' ]
label_map: { 0: face, 1: mobile, 2: person, 3: hand, 4: smoking, 5: drinking, 6: other_item, 7: food, 8: mounted_cp }
label_name_map: { face: 0, mobile: 1, person: 2, hand: 3, smoking: 4, drinking: 5, other_item: 6, food: 7, mounted_cp: 8}
ground_truth_label_map_dict: {
    "Not_distracted": 1,
    "Looking_left/right": 1,
    "looking_down": 7,
    "mobile_usage": 2,
    "other_distraction": 3,
    "properly_fastened": 4,
    "loosely_fastened": 4,
    "Reflective Jacket": 5,
    "Full Obstruction": 6,
    "smoking": 8,
    "eating": 9,
    "drinking": 10,
    "holding_any_object_in_hand": 11,
    "not_sure": 12,
}
moving_average_decay: 0.9998
box_loss_weight: 50.0
iou_loss_weight: 1.0
apply_weighted_cls_loss: false
img_cls_loss_weights: [1.0, 2.0, 5.0, 1.0, 2.0, 5.0, 3.0, 5.0, 5.0, 4.0, 3.0]
nms_configs: { "method": "gaussian", "iou_thresh": 0.1 }
num_epochs: 50
learning_rate: 0.08
lr_warmup_epoch: 5
lr_warmup_init: 0.008
mixed_precision: true
clip_gradients_norm: 10.0
jitter_min: 1.0
jitter_max: 1.0
crop: True
crop_offset_720p: [ 0, 256 ]
crop_offset_1080p: [0, 384]
input_rand_hflip: false
apply_augmentation: False


# YOLOv5 ðŸš€ by Ultralytics, GPL-3.0 license

# Parameters
nc: 9 # number of classes
depth_multiple: 0.33  # model depth multiple
width_multiple: 0.25  # layer channel multiple
anchors:
  - [19,27,  44,40,  38,94]  # P3/8
  - [96,68,  86,152,  180,137]  # P4/16
  - [140,301,  303,264,  238,542]  # P5/32
  - [436,615,  739,380,  925,792]  # P6/64

# YOLOv5 v6.0 backbone
backbone:
  # [from, number, module, args]
  [[-1, 1, Conv, [64, 6, 2, 2]],  # 0-P1/2
   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4
   [-1, 3, C3, [128]],
   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8
   [-1, 6, C3, [256]],
   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16
   [-1, 9, C3, [512]],
   [-1, 1, Conv, [768, 3, 2]],  # 7-P5/32
   [-1, 3, C3, [768]],
   [-1, 1, Conv, [1024, 3, 2]],  # 9-P6/64
   [-1, 3, C3, [1024]],
   [-1, 1, SPPF, [1024, 5]],  # 11
  ]

# YOLOv5 v6.0 head
# Heads needed for driver distraction
heads:
  detection:
    start_layer: 12
    layers: [
      [-1, 1, Conv, [768, 1, 1]],
      [-1, 1, nn.Upsample, [None, 2, 'nearest']],
      [[-1, 8], 1, Concat, [1]],  # cat backbone P5
      [-1, 3, C3, [768, False]],  # 15

      [-1, 1, Conv, [512, 1, 1]],
      [-1, 1, nn.Upsample, [None, 2, 'nearest']],
      [[-1, 6], 1, Concat, [1]],  # cat backbone P4
      [-1, 3, C3, [512, False]],  # 19

      [-1, 1, Conv, [256, 1, 1]],
      [-1, 1, nn.Upsample, [None, 2, 'nearest']],
      [[-1, 4], 1, Concat, [1]],  # cat backbone P3
      [-1, 3, C3, [256, False]],  # 23 (P3/8-small)

      [-1, 1, Conv, [256, 3, 2]],
      [[-1, 20], 1, Concat, [1]],  # cat head P4
      [-1, 3, C3, [512, False]],  # 26 (P4/16-medium)

      [-1, 1, Conv, [512, 3, 2]],
      [[-1, 16], 1, Concat, [1]],  # cat head P5
      [-1, 3, C3, [768, False]],  # 29 (P5/32-large)

      [-1, 1, Conv, [768, 3, 2]],
      [[-1, 12], 1, Concat, [1]],  # cat head P6
      [-1, 3, C3, [1024, False]],  # 32 (P6/64-xlarge)

      [[23, 26, 29, 32], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5, P6)
      ]    
  
  pose: 
    start_layer: 24
    layers: [
    [19, 1, nn.Upsample, [None, 2, "nearest"]], # 24
    [15, 1, nn.Upsample, [None, 4, "nearest"]], # 25
    #[32, 1, nn.Upsample, [None, 8, "nearest"]], # 
    [[23, 24, -1], 1, Concat, [1]],                   # 26

    [-1, 1, Conv, ['ch[26]/gw', 1, 1, 'same']], # 27
    [-1, 1, Conv, ['ch[26]/gw*2', 3, 1, 'same']], # 28
    
    [-1, 1, Conv, ['ch[26]/gw', 1, 1, 'same']], # 29
    [-1, 1, Conv, ['ch[26]/gw*2', 3, 1, 'same']], # 30
    
    #[-1, 1, Conv, ['ch[26]/gw', 1, 1, 'same']],
    #[-1, 1, Conv, ['ch[26]/gw*2', 3, 1, 'same']],
    
    [-1, 1, nn.Conv2d, ['num_pose_kps/gw', 1, 1, 'same']]
  ]

  img_classification: 
    #start_layer: 10
    start_layer: 11
    #start_layer: 24
    layers: [
      # this layer is implemeted in code!!
      #["pose[-1, 26]", 1, Concat, [1]],                   # 25

      #[-1, 1, Conv, ['ch[-1]/gw', 1, 1]], # 26
      #[-1, 1, Conv, ['ch[-1]/gw*2', 3, 1]], # 27

      #[9, 1, Conv, ['ch[8]/gw', 1]], # 10 1x1 Conv in and out channels are same
      [8, 1, Conv, ['ch[10]/gw', 3, 1, 'same']], # 9 3x3 Conv in and out channels are same
      [-1, 1, Conv, ['ch[-1]/gw', 3, 1, 'same']], # 10 3x3 Conv in and out channels are same
      [-1, 1, Conv, ['ch[-1]/gw', 3, 1, 'same']], # 11 3x3 Conv in and out channels are same
      
      [-1, 1, Conv, ['ch[-1]/gw', 1]], # 27 1x1 Conv in and out channels are same
      [-1, 1, nn.AdaptiveAvgPool2d, [1]],
      [-1, 1, nn.Flatten, []],
      #[-1, 1, nn.Linear, ['ch[-2]', num_classification_classes]] # 15 Dense Layer

      #[-1, 1, nn.Linear, ['ch[-2]', 'ch[-2]//2']], # 30 Dense Layer
      #[-1 ,1, nn.LeakyReLU, []],
      [-1, 1, nn.Linear, ['ch[-2]', 'ch[-2]//2']], # 32 Dense Layer
      [-1 ,1, nn.LeakyReLU, []],
      [-1, 1, nn.Linear, ['ch[-2]', num_classification_classes]], # 34 Dense Layer
    ]

