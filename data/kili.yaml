# YOLOv5 🚀 by Ultralytics, GPL-3.0 license
# Kili project dataset https://cloud.kili-technology.com/label/projects/ckysuic0y0ldc0lvoeltld164/menu/analytics
# Before running, make sure that the KILI_API_KEY environment variable is set with the API key obtained from Kili
# (in https://cloud.kili-technology.com/label/my-account/api-key if you are using the cloud version)
#
# Example usage: python train.py --data kili.yaml
# parent
# ├── yolov5
# └── datasets
#     └── kili  ← downloads here
#
# There are 3 fields you must change:
# - path: ../datasets/kili/<YOUR_KILI_PROJECT_ID> -  your Kili project ID
# - names: ["<CLASS_1>", "<CLASS_2>", "<CLASS_3>"] - the classes of your classification problem
# - nc: 3  : the class names list cardinality
#
# You can also change the download script to your convenience, and read parameters from the yaml by means of the `yaml` dictionary.

# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]
path: ../datasets/kili/<YOUR_KILI_PROJECT_ID> # dataset root dir with your Kili project ID
train: images/train # train images (relative to 'path')
val: images/val # val images (relative to 'path')
test: images/test # test images (optional)

# Classes
names: ["<CLASS_1>", "<CLASS_2>", "<CLASS_3>"] # class names, must match your Kili project class names.
nc: 3 # number of classes (cardinality of the list above)

# The proportions of he training and validation dataset, the sum should be < 1.0. The remainder is used as the test set.
train_val_proportions:
  - 0.8
  - 0.1

# Download script/URL (optional)
download: |
  import math
  import os
  import re
  import time

  from kili.client import Kili
  import requests
  from tqdm.auto import tqdm

  print("Downloading datasets from Kili")
  train_val_proportions = yaml['train_val_proportions']
  path = yaml.get('path', '')
  if '/kili/' not in path:
      raise ValueError("'path' field in config must contain '/kili/'")

  project_id = path.split('/')[-1]
  kili = Kili()
  total = kili.count_assets(project_id=project_id)
  first = 100
  assets = []
  for skip in tqdm(range(0, total, first)):
      assets += kili.assets(
          project_id=project_id,
          first=first,
          skip=skip,
          disable_tqdm=True,
          fields=[
              'id',
              'content',
              'labels.createdAt',
              'labels.jsonResponse',
              'labels.labelType'])
  assets = [{
          **a,
          'labels': [
              l for l in sorted(a['labels'], key=lambda l: l['createdAt']) \
                  if l['labelType'] in ['DEFAULT', 'REVIEW']
          ][-1:],
      } for a in assets]
  assets = [a for a in assets if len(a['labels']) > 0]

  n_train_assets = math.floor(len(assets) * train_val_proportions[0])
  n_val_assets = math.floor(len(assets) * train_val_proportions[1])

  assets_splits = {
      "train": assets[:n_train_assets],
      "val": assets[n_train_assets : n_train_assets + n_val_assets],
      "test": assets[n_train_assets + n_val_assets :],
  }

  for name_split, assets_split in assets_splits.items():

      path_split = os.path.join(path, yaml.get(name_split, ''))
      print(f"Building {name_split} in {path_split} ...")
      os.makedirs(path_split, exist_ok=True)
      for asset in tqdm(assets_split):
          tic = time.time()
          img_data = requests.get(asset['content'], headers={
                  'Authorization': f'X-API-Key: {os.environ["KILI_API_KEY"]}',
              }).content
          with open(os.path.join(path_split, asset['id'] + '.jpg'), 'wb') as handler:
              handler.write(img_data)
          toc = time.time() - tic
          throttling_per_call = 60.0 / 250 # Kili API calls are limited to 250 per minute
          if toc < throttling_per_call:
              time.sleep(throttling_per_call - toc)
      names = yaml.get('names', [])
      path_labels = re.sub('/images/', '/labels/', path_split)
      print(path_labels)
      os.makedirs(path_labels, exist_ok=True)
      for asset in assets_split:
          with open(os.path.join(path_labels, asset['id'] + '.txt'), 'w') as handler:
              json_response = asset['labels'][0]['jsonResponse']
              for job in json_response.values():
                  for annotation in job.get('annotations', []):
                      name = annotation['categories'][0]['name']
                      try:
                          category = names.index(name)
                      except ValueError:
                          pass
                      bounding_poly = annotation.get('boundingPoly', [])
                      if len(bounding_poly) < 1:
                          continue
                      if 'normalizedVertices' not in bounding_poly[0]:
                          continue
                      normalized_vertices = bounding_poly[0]['normalizedVertices']
                      x_s = [vertice['x'] for vertice in normalized_vertices]
                      y_s = [vertice['y'] for vertice in normalized_vertices]
                      x_min, y_min = min(x_s), min(y_s)
                      x_max, y_max = max(x_s), max(y_s)
                      _x_, _y_ = (x_max + x_min) / 2, (y_max + y_min) / 2
                      _w_, _h_ = x_max - x_min, y_max - y_min
                      handler.write(f'{category} {_x_} {_y_} {_w_} {_h_}\n')
