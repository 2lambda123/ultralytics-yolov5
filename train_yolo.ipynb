{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Repsycle.interact_utils import InteractAPI\n",
    "import torchvision\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn, optim\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim import lr_scheduler\n",
    "import random\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "import base64\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import json\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import time\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import yaml\n",
    "import shutil\n",
    "from IPython.display import JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set interact parameters \n",
    "username = None\n",
    "assert username is not None\n",
    "password = None\n",
    "assert password is not None\n",
    "api_root = \"https://interact-api.psycle.io/api/v1\"\n",
    "project_id = None  # Project name\n",
    "assert password is not None\n",
    "analysis_id = None  # Analysis name\n",
    "assert analysis_id is not None\n",
    "\n",
    "filters = {'annotations__isnull': False}\n",
    "\n",
    "# Set file structure \n",
    "project_path = f'{os.getcwd()}'\n",
    "\n",
    "image_folder = f\"{project_path}/images\"\n",
    "datas_folder = f\"{project_path}/annotations\"\n",
    "weights_folder = f'{project_path}/weights'\n",
    "augmented_image_folder = f'{project_path}/augmented_images'\n",
    "\n",
    "datas_path = f'{datas_folder}/datas.json'\n",
    "train_annotations_path = f'{datas_folder}/train_annotations.json'\n",
    "val_annotations_path = f'{datas_folder}/val_annotations.json'\n",
    "\n",
    "\n",
    "image_extension = 'png'\n",
    "\n",
    "seed = 42\n",
    "\n",
    "# Create file structure\n",
    "if not os.path.exists(image_folder):\n",
    "    os.mkdir(image_folder)\n",
    "if not os.path.exists(datas_folder):\n",
    "    os.mkdir(datas_folder)\n",
    "if not os.path.exists(weights_folder):\n",
    "    os.mkdir(weights_folder)\n",
    "if not os.path.exists(augmented_image_folder):\n",
    "    os.mkdir(augmented_image_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json(path,file_to_save):\n",
    "    with open(path,'w') as f:\n",
    "        json.dump(file_to_save, f)\n",
    "        \n",
    "def open_json(path):\n",
    "    with open(path, 'r') as f:\n",
    "        file = json.load(f)\n",
    "    return file\n",
    "\n",
    "def save_yaml(path, file_to_save):\n",
    "    with open(path, 'w') as f:\n",
    "        file = yaml.dump(file_to_save, f)\n",
    "    return file\n",
    "\n",
    "def open_yaml(path):\n",
    "    with open(path, 'r') as f:\n",
    "            file = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    return file\n",
    "\n",
    "def convert(size, box):\n",
    "    dw = 1./(size[0])\n",
    "    dh = 1./(size[1])\n",
    "    x = (box[0] + box[1])/2.0 - 1\n",
    "    y = (box[2] + box[3])/2.0 - 1\n",
    "    w = box[1] - box[0]\n",
    "    h = box[3] - box[2]\n",
    "    x = x*dw\n",
    "    w = w*dw\n",
    "    y = y*dh\n",
    "    h = h*dh\n",
    "    return (x,y,w,h)\n",
    "\n",
    "def get_image_path(data_id: str):\n",
    "    return f'{image_folder}/{data_id}.{image_extension}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactAPI = InteractAPI(username, password, api_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download all annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datas = interactAPI.get_datas(project_id, **filters)\n",
    "save_json(datas_path, datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = open_json(datas_path)\n",
    "print(f'Number of images: {len(datas)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_int = {}\n",
    "for idx, label in enumerate(datas[0]['annotations'][0]['analysis']['labels']):\n",
    "    label_to_int[label] = idx\n",
    "label_to_int['background'] = idx+1\n",
    "int_to_label = {v: k for k, v in label_to_int.items()}\n",
    "\n",
    "print(f'label_to_int: {label_to_int}')\n",
    "print(f'int_to_label: {int_to_label}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download all images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = open_json(datas_path)\n",
    "\n",
    "for data in tqdm(datas):\n",
    "    data_id = data['id']\n",
    "    image_path = get_image_path(data_id)\n",
    "    if not os.path.exists(image_path):\n",
    "        image = interactAPI.get_image(project_id, data_id, base64=True)\n",
    "        image = base64.b64decode(image)\n",
    "        image = Image.open(BytesIO(image))\n",
    "        image.save(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = open_json(datas_path)\n",
    "filtered_datas = {}\n",
    "\n",
    "for data in datas:\n",
    "    data_id = data['id']\n",
    "    \n",
    "    labels = []\n",
    "    coordinates = []\n",
    "    viewed = data['viewed']\n",
    "    shape = cv2.imread(get_image_path(data_id)).shape\n",
    "    annotations = data['annotations']\n",
    "    \n",
    "    if len(annotations) > 0:\n",
    "        for idx in range(len(annotations)):\n",
    "            label = annotations[idx]['label']\n",
    "            x1, y1, x2, y2 = annotations[idx]['coordinates']\n",
    "            coordinate = convert(size = (shape[1], shape[0]), box=(x1, x2, y1, y2))\n",
    "\n",
    "            labels.append(label)\n",
    "            coordinates.append(coordinate)\n",
    "            \n",
    "    else :\n",
    "        labels = ['background']\n",
    "        coordinates = []\n",
    "    \n",
    "    if data['viewed']:        \n",
    "        filtered_datas[data_id] = {\n",
    "            'label': labels,\n",
    "            'coordinates': coordinates, \n",
    "            'shape': shape\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize some image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height = 4, 4\n",
    "fig, axs = plt.subplots(width,height, figsize=(15, 15))\n",
    "fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "axs = axs.ravel()\n",
    "\n",
    "keys = list(filtered_datas.keys())\n",
    "annotations = list(filtered_datas.values())\n",
    "idxs = np.random.randint(0, len(keys), width * height)\n",
    "\n",
    "for plot_idx, i in enumerate(idxs):\n",
    "    data_id = keys[i]\n",
    "    img = cv2.imread(get_image_path(data_id))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    h,w,_ = img.shape\n",
    "    size = (w,h)\n",
    "    coordinates = annotations[i]['coordinates']\n",
    "    classes = annotations[i]['label']\n",
    "    \n",
    "    for coordinate in coordinates:\n",
    "        x, y, w, h = coordinate\n",
    "        p1 = (int( (x - w/2) * size[0]), int( (y - h/2) * size[1]))\n",
    "        p2 = (int( (x + w/2) * size[0]), int((y + h/2) * size[1]))\n",
    "        img = cv2.rectangle(img, p1, p2, color=(255, 0, 0), thickness=3)\n",
    "\n",
    "    axs[plot_idx].imshow(img)\n",
    "    axs[plot_idx].set_title(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for key, value in filtered_datas.items():\n",
    "    for label in value['label']:\n",
    "        labels.append(label)\n",
    "\n",
    "plt.plot(figsize=(20,20))\n",
    "plt.hist(labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coordinates distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates = []\n",
    "for key, value in filtered_datas.items():\n",
    "    for coordinate in value['coordinates']:\n",
    "        coordinates.append(coordinate)\n",
    "coordinates = np.asarray(coordinates)\n",
    "plt.figure(figsize = (5, 5))\n",
    "plt.scatter(coordinates[:,0], coordinates[:, 1], s = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "for key, value in filtered_datas.items():\n",
    "    y.append(value['label'][0])\n",
    "\n",
    "image_classes = [value['label'] for key, value in filtered_datas.items()]\n",
    "image_coordinates = [value['coordinates'] for key, value in filtered_datas.items()]\n",
    "image_ids = list(filtered_datas.keys())\n",
    "\n",
    "X = np.asarray(image_ids)\n",
    "y = np.asarray(y)\n",
    "\n",
    "val_size = int(0.2*len(X))\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=val_size, random_state=seed)\n",
    "split = sss.split(X, y)\n",
    "train_index, test_index = next(split)\n",
    "\n",
    "\n",
    "train_annotations = {}\n",
    "\n",
    "for idx in train_index:\n",
    "    train_annotations[image_ids[idx]] = {\n",
    "        'label':image_classes[idx], \n",
    "        'coordinates':image_coordinates[idx]\n",
    "    }\n",
    "\n",
    "val_annotations = {}\n",
    "for idx in test_index:\n",
    "    val_annotations[image_ids[idx]] = {\n",
    "        'label':image_classes[idx], \n",
    "        'coordinates':image_coordinates[idx]\n",
    "    }\n",
    "\n",
    "save_json(train_annotations_path, train_annotations)\n",
    "save_json(val_annotations_path, val_annotations)\n",
    "\n",
    "print(f'Number of annotations for training: {len(train_annotations)}')\n",
    "print(f'Number of annotations for validation: {len(val_annotations)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for key, value in train_annotations.items():\n",
    "    for label in value['label']:\n",
    "        labels.append(label)\n",
    "\n",
    "plt.plot(figsize=(20,20))\n",
    "plt.hist(labels)\n",
    "plt.show()\n",
    "print('Training distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for key, value in val_annotations.items():\n",
    "    for label in value['label']:\n",
    "        labels.append(label)\n",
    "\n",
    "plt.plot(figsize=(20,20))\n",
    "plt.hist(labels)\n",
    "plt.show()\n",
    "print('Validation distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load on yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone git@github.com:PsycleResearch/yolov5.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_annotations_folder =f'{os.getcwd()}/yolov5/yolov5/data/labels/train/'\n",
    "val_annotations_folder =f'{os.getcwd()}/yolov5/yolov5/data/labels/val/'\n",
    "\n",
    "train_images_folder = f'{os.getcwd()}/yolov5/yolov5/data/images/train/'\n",
    "val_images_folder = f'{os.getcwd()}/yolov5/yolov5/data/images/val/'\n",
    "\n",
    "hyperparameters_scratch = f'{os.getcwd()}/yolov5/yolov5/data/hyp.scratch.yaml'\n",
    "hyperparameters_finetune = f'{os.getcwd()}/yolov5/yolov5/data/hyp.finetune.yaml'\n",
    "\n",
    "yolov5s = f'{os.getcwd()}/yolov5/yolov5/data/yolov5s.yaml'\n",
    "\n",
    "dataset_path = f'{os.getcwd()}/yolov5/yolov5/data/dataset.yaml'\n",
    "\n",
    "nb_classes = len(int_to_label) - 1  # remove background class\n",
    "\n",
    "# Create file structure\n",
    "if not os.path.exists(train_annotations_folder):\n",
    "    os.makedirs(train_annotations_folder)\n",
    "if not os.path.exists(val_annotations_folder):\n",
    "    os.makedirs(val_annotations_folder)\n",
    "    \n",
    "if not os.path.exists(train_images_folder):\n",
    "    os.makedirs(train_images_folder)\n",
    "if not os.path.exists(val_images_folder):\n",
    "    os.makedirs(val_images_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = list(label_to_int.keys())\n",
    "names.remove('background')\n",
    "\n",
    "dataset = {\n",
    "    'train': f'{os.getcwd()}/yolov5/yolov5/data/images/train/',\n",
    "    'val': f'{os.getcwd()}/yolov5/yolov5/data/images/val/',\n",
    "    'nc': nb_classes,\n",
    "    'names': names\n",
    "}\n",
    "\n",
    "save_yaml(dataset_path, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolov5s_parameters = {\n",
    "    \n",
    "    'nc': nb_classes, \n",
    "    'depth_multiple': 0.33,\n",
    "    'width_multiple': 0.5,\n",
    "    'anchors': [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]],\n",
    "    \n",
    "    'backbone':\n",
    "    \n",
    "    [[-1, 1, 'Focus', [64, 3]],\n",
    "     [-1, 1, 'Conv', [128, 3, 2]],\n",
    "     [-1, 3, 'BottleneckCSP', [128]],\n",
    "     [-1, 1, 'Conv', [256, 3, 2]],\n",
    "     [-1, 9, 'BottleneckCSP', [256]],\n",
    "     [-1, 1, 'Conv', [512, 3, 2]],\n",
    "     [-1, 9, 'BottleneckCSP', [512]],\n",
    "     [-1, 1, 'Conv', [1024, 3, 2]],\n",
    "     [-1, 1, 'SPP', [1024, [5, 9, 13]]],\n",
    "     [-1, 3, 'BottleneckCSP', [1024, False]]],\n",
    "    \n",
    "    'head':\n",
    "    \n",
    "    [[-1, 1, 'Conv', [512, 1, 1]],\n",
    "     [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']],\n",
    "     [[-1, 6], 1, 'Concat', [1]],\n",
    "     [-1, 3, 'BottleneckCSP', [512, False]],\n",
    "     [-1, 1, 'Conv', [256, 1, 1]],\n",
    "     [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']],\n",
    "     [[-1, 4], 1, 'Concat', [1]],\n",
    "     [-1, 3, 'BottleneckCSP', [256, False]],\n",
    "     [-1, 1, 'Conv', [256, 3, 2]],\n",
    "     [[-1, 14], 1, 'Concat', [1]],\n",
    "     [-1, 3, 'BottleneckCSP', [512, False]],\n",
    "     [-1, 1, 'Conv', [512, 3, 2]],\n",
    "     [[-1, 10], 1, 'Concat', [1]],\n",
    "     [-1, 3, 'BottleneckCSP', [1024, False]],\n",
    "     [[17, 20, 23], 1, 'Detect', ['nc', 'anchors']]]\n",
    "}\n",
    "\n",
    "save_yaml(yolov5s, yolov5s_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolov5_finetune_hyperparameters = {\n",
    "    \n",
    "    'lr0': 0.001,\n",
    "    'lrf': 0.001,\n",
    "    'momentum': 0.843,\n",
    "    'weight_decay': 0.00036,\n",
    "    'warmup_epochs': 2.0,\n",
    "    'warmup_momentum': 0.5,\n",
    "    'warmup_bias_lr': 0.05,\n",
    "    'box': 0.0296,\n",
    "    'cls': 0.243,\n",
    "    'cls_pw': 0.631,\n",
    "    'obj': 0.301,\n",
    "    'obj_pw': 0.911,\n",
    "    'iou_t': 0.2,\n",
    "    'anchor_t': 2.91,\n",
    "    'fl_gamma': 0.0,\n",
    "    'hsv_h': 0,\n",
    "    'hsv_s': 0,\n",
    "    'hsv_v': 0,\n",
    "    'degrees': 0.373,\n",
    "    'translate': 0.245,\n",
    "    'scale': 0.1,\n",
    "    'shear': 0.0,\n",
    "    'perspective': 0.0,\n",
    "    'flipud': 0.5,\n",
    "    'fliplr': 0.5,\n",
    "    'mixup': 0.0,\n",
    "    'mosaic': 1.0,\n",
    "    'copy_paste': 0.0\n",
    "}\n",
    "\n",
    "save_yaml(hyperparameters_finetune, yolov5_finetune_hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert datas for yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy images/annotations to yolo folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_annotations = open_json(train_annotations_path)\n",
    "val_annotations = open_json(val_annotations_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for annotations_set in [(train_annotations, train_images_folder, train_annotations_folder), (val_annotations, val_images_folder, val_annotations_folder)]:\n",
    "    for data_id, annotation in annotations_set[0].items():\n",
    "        label_file = open(annotations_set[2] + data_id + '.txt', 'w')\n",
    "        \n",
    "        for idx in range(len(annotation['label'])):\n",
    "            if annotation['label'][idx] != 'background':\n",
    "                c = label_to_int[annotation['label'][idx]]\n",
    "                x, y, w, h = annotation['coordinates'][idx]\n",
    "                label = f'{c} {x} {y} {w} {h}\\n'\n",
    "            else :\n",
    "                label = ''\n",
    "                                \n",
    "            shutil.copyfile(\n",
    "                get_image_path(data_id), \n",
    "                annotations_set[1] + data_id + '.bmp'\n",
    "            )\n",
    "            label_file.write(label)\n",
    "        label_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train (from yolov5 Psycle lib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python yolov5/train.py --weights yolov5/weights/yolov5s.pt --cfg yolov5/data/yolov5s.yaml --data yolov5/data/dataset.yaml --hyp yolov5/data/hyp.finetune.yaml --epochs 200 --batch-size 8 --imgsz 640 --adam\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentations = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'seed':seed\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_annotations_path) as f:\n",
    "    train_annotations = json.load(f)\n",
    "training_set = list(train_annotations.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(val_annotations_path) as f:\n",
    "    val_annotations = json.load(f)\n",
    "val_set = list(val_annotations.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_dict = {\n",
    "    'name':'',   # TODO\n",
    "    'analysis_id':analysis_id, \n",
    "    'hyperparameters': yolov5_finetune_hyperparameters, \n",
    "    'labels_output_mapping': label_to_int, \n",
    "    'train_set': training_set, \n",
    "    'validation_set':val_set,\n",
    "    'metadata':{\n",
    "        'model':'YOLOV5S', \n",
    "    }\n",
    "}\n",
    "\n",
    "weights_path = None  # TODO\n",
    "assert weights_path is not None\n",
    "weights_choice = \"\"  # TODO\n",
    "assert weights_choice is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_id = interactAPI.post_training(post_dict)\n",
    "print(training_id)\n",
    "if interactAPI.post_weights(weights_path, training_id['id']) == 204:\n",
    "    print('Sucess')\n",
    "interactAPI.put_training_weights_choice('', training_id['id'])  # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
